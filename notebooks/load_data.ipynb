{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599404327742",
   "display_name": "Python 3.6.10 64-bit ('nlp_text_similarity': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset \n",
    "\n",
    "* author: steeve laquitaine\n",
    "\n",
    "* Workload (1 hour to debug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import time\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set data paths  \n",
    "os.chdir('..') # should be in my_project/notebooks/\n",
    "data_path = os.getcwd()\n",
    "raw_data_path       = data_path + \"/data/01_raw/\"\n",
    "preprocessed_data_path = data_path + \"/data/02_preprocessed/\"\n",
    "url                 = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz' \n",
    "download_output     = raw_data_path + \"aclImdb_v1.tar.gz\"\n",
    "train_path = preprocessed_data_path + \"train.csv\"\n",
    "test_path = preprocessed_data_path + \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## download (to debug)\n",
    "## !! FileNotFoundError: No such file or directory: './data/01_raw/dataset_compressed.tar.gzoul9mi4u.tmp'\n",
    "# print(url)\n",
    "# print(download_output)\n",
    "# wget.download(url, download_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_dataset(data_file, output_folder):\n",
    "    # decompress dataset file in dataset/ folder\n",
    "    tic = time.time()\n",
    "    tar = tarfile.open(data_file)\n",
    "    tar.extractall(path=output_folder)\n",
    "    tar.close()\n",
    "    toc = time.time()\n",
    "    print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# decompress\n",
    "decompress_dataset(download_output, raw_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete compressed file\n",
    "os.remove(download_output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(path, CLASSES):\n",
    "    texts, labels = [], []\n",
    "    for idx, label in enumerate(CLASSES):\n",
    "        for fname in (path / label).glob('*.*'):\n",
    "            texts.append(fname.open('r', encoding='utf-8').read())\n",
    "            labels.append(idx)\n",
    "    return np.array(texts), np.array(labels)\n",
    "\n",
    "def extract_transform_load_dataset(raw_data_path, output_path, timeit=True):\n",
    "  \n",
    "    tic = time.time()\n",
    "    \n",
    "    # 1 - Init variables\n",
    "    BOS = 'xbos'  # beginning-of-sentence tag\n",
    "    FLD = 'xfld'  # data field tag\n",
    "    CLASSES = ['neg', 'pos', 'unsup']\n",
    "    col_names = ['sentiment', 'review']\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 2 - Build output folders\n",
    "    PATH = Path(raw_data_path + 'aclImdb/')\n",
    "    CLAS_PATH = Path(output_path)\n",
    "\n",
    "    # 3 - Process and store train dataset\n",
    "    print(PATH)\n",
    "    trn_texts, trn_labels = get_texts(PATH / 'train', CLASSES)\n",
    "    print(len(trn_texts))\n",
    "    print(len(trn_labels))\n",
    "    df_trn = pd.DataFrame({'review': trn_texts, 'sentiment': trn_labels}, columns=col_names)\n",
    "    df_trn[df_trn['sentiment'] != 2].to_csv(CLAS_PATH / 'train.csv', index=False)\n",
    "    \n",
    "    # 4 - Process and store evaluation dataset\n",
    "    val_texts, val_labels = get_texts(PATH / 'test', CLASSES)\n",
    "    df_val = pd.DataFrame({'review': val_texts, 'sentiment': val_labels}, columns=col_names)\n",
    "    df_val.to_csv(CLAS_PATH / 'test.csv', index=False)\n",
    "    \n",
    "    # 5 - Store classes\n",
    "    (CLAS_PATH / 'classes.txt').open('w', encoding='utf-8').writelines(f'{o}\\n' for o in CLASSES)\n",
    "\n",
    "    toc = time.time()\n",
    "    print(np.round(toc - tic, 2), ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/Users/steeve_laquitaine/Desktop/CodeHub/nlp_txt_similarity/data/01_raw/aclImdb\n75000\n75000\n54.57  sec\n"
    }
   ],
   "source": [
    "# ETL (1 min)\n",
    "extract_transform_load_dataset(raw_data_path, preprocessed_data_path, timeit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_path, test_path, sample=5000):\n",
    "    \n",
    "    tic = time.time()\n",
    "\n",
    "    # TRAIN\n",
    "    train_dataset = pd.read_csv(train_path).sample(n=sample)\n",
    "\n",
    "    # preview data\n",
    "    print(train_dataset.head())\n",
    "\n",
    "    # build train and test datasets\n",
    "    train_reviews = np.array(train_dataset['review'])\n",
    "    train_sentiments = np.array(train_dataset['sentiment'])\n",
    "\n",
    "    # TEST\n",
    "    test_dataset = pd.read_csv(test_path).sample(n=sample)\n",
    "    test_reviews = np.array(test_dataset['review'])\n",
    "    test_sentiments = np.array(test_dataset['sentiment'])\n",
    "    print('(load_dataset)', time.time() - tic)\n",
    "\n",
    "    toc = time.time()\n",
    "    print(('Completed'), toc - tic)\n",
    "\n",
    "    return train_sentiments, test_sentiments, train_reviews, test_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sentiment                                             review\n16560          1  I saw this film in the worst possible circumst...\n10876          0  SPOILERS THROUGHOUT!!!!<br /><br />I had read ...\n15889          1  Time and time again, I've stated that if peopl...\n12920          1  One of my favourite films. It has everything -...\n13565          1  Maybe I'm a sap but this is the sweetest movie...\n(load_dataset) 0.5145790576934814\nCompleted 0.5147788524627686\n"
    }
   ],
   "source": [
    "# load datasets (arrays, 1 sec)\n",
    "Y_train, Y_test, X_train, X_test = load_dataset(train_path, test_path, sample=5000)\n"
   ]
  }
 ]
}