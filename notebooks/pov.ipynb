{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599488187183",
   "display_name": "Python 3.6.10 64-bit ('nlp_text_similarity': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Text Similarity\n",
    "### Techniques: tf-idf + svd\n",
    "### Technos: pyspark\n",
    "### Applications: e.g., collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "* Spark 2.4.4 is installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup environment variables\n",
    "\n",
    "* workload: 1 hour to config (first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup SPARK environment variables\n",
    "import os\n",
    "import sys  \n",
    "os.environ['SPARK_HOME'] = '/usr/local/Cellar/apache-spark/2.4.4/libexec'\n",
    "os.environ['PYSPARK_PYTHON'] = '/Applications/anaconda3/envs/nlp_text_similarity/bin/python'  \n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/Applications/anaconda3/envs/nlp_text_similarity/bin/python'  \n",
    "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home'\n",
    "os.environ['PYTHONPATH'] = os.environ['SPARK_HOME'] + '/python/lib/'\n",
    "sys.path.insert(0, os.environ['SPARK_HOME'] + '/python/lib/py4j-0.10.7-src.zip')\n",
    "sys.path.insert(0, os.environ['SPARK_HOME'] + '/python/lib/pyspark.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list dependencies\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset path\n",
    "os.chdir('..')\n",
    "project_path = os.getcwd()\n",
    "dataset_path = 'data/02_preprocessed/train.csv'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sparkSession\n",
    "sparkSession = SparkSession.builder.appName(\"my_app\").master(\"local[*]\").getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x12372e5f8>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://steeve.home:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>my_app</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# print spark session config\n",
    "sparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dataset size: (25000, 2)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sentiment                                             review\n0          0  Working with one of the best Shakespeare sourc...\n1          0  Well...tremors I, the original started off in ...\n2          0  Ouch! This one was a bit painful to sit throug...\n3          0  I've seen some crappy movies in my life, but t...\n4          0  \"Carriers\" follows the exploits of two guys an...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Working with one of the best Shakespeare sourc...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Well...tremors I, the original started off in ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Ouch! This one was a bit painful to sit throug...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>I've seen some crappy movies in my life, but t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>\"Carriers\" follows the exploits of two guys an...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "# Load imdb dataset as pandas dataframe (<1 sec)\n",
    "dataset_df = pd.read_csv(dataset_path)\n",
    "print('Dataset size:', dataset_df.shape)\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   sentiment                                             review\n0          0  Working with one of the best Shakespeare sourc...\n1          0  Well...tremors I, the original started off in ...\n2          0  Ouch! This one was a bit painful to sit throug...\n3          0  I've seen some crappy movies in my life, but t...\n4          0  \"Carriers\" follows the exploits of two guys an...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Working with one of the best Shakespeare sourc...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Well...tremors I, the original started off in ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Ouch! This one was a bit painful to sit throug...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>I've seen some crappy movies in my life, but t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>\"Carriers\" follows the exploits of two guys an...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# filter dataset (keep reviews)\n",
    "reviews_dataset_df = dataset_df[['sentiment','review']]\n",
    "reviews_dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+---------+--------------------+\n|sentiment|              review|\n+---------+--------------------+\n|        0|Working with one ...|\n|        0|Well...tremors I,...|\n|        0|Ouch! This one wa...|\n|        0|I've seen some cr...|\n|        0|\"Carriers\" follow...|\n|        0|I had been lookin...|\n|        0|Effect(s) without...|\n|        0|This picture star...|\n|        0|I chose to see th...|\n|        0|This film has to ...|\n|        0|I felt brain dead...|\n|        0|A young scientist...|\n|        0|Inept, boring, an...|\n|        0|From the first ti...|\n|        0|I find it hard to...|\n|        0|I actually saw Ch...|\n|        0|I went to school ...|\n|        0|I haven't seen th...|\n|        0|I haven't seen an...|\n|        0|One would think t...|\n+---------+--------------------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "# create spark dataframe (2 sec)\n",
    "dataset_spark = sparkSession.createDataFrame(data=reviews_dataset_df, schema=['sentiment','review'])\n",
    "dataset_spark.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "root\n |-- sentiment: long (nullable = true)\n |-- review: string (nullable = true)\n\n"
    }
   ],
   "source": [
    "# check dataset schema\n",
    "dataset_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Words data schema:\nroot\n |-- sentiment: long (nullable = true)\n |-- review: string (nullable = true)\n |-- words: array (nullable = true)\n |    |-- element: string (containsNull = true)\n\n+---------+--------------------+--------------------+--------------------+\n|sentiment|              review|               words|         rawFeatures|\n+---------+--------------------+--------------------+--------------------+\n|        0|Working with one ...|[working, with, o...|(262144,[9639,172...|\n|        0|Well...tremors I,...|[well...tremors, ...|(262144,[14,1624,...|\n|        0|Ouch! This one wa...|[ouch!, this, one...|(262144,[2437,912...|\n|        0|I've seen some cr...|[i've, seen, some...|(262144,[14,3026,...|\n|        0|\"Carriers\" follow...|[\"carriers\", foll...|(262144,[14,1804,...|\n+---------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\ntf-idf data schema:\nroot\n |-- sentiment: long (nullable = true)\n |-- review: string (nullable = true)\n |-- words: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- rawFeatures: vector (nullable = true)\n |-- features: vector (nullable = true)\n\n+---------+--------------------+\n|sentiment|            features|\n+---------+--------------------+\n|        0|(262144,[9639,172...|\n|        0|(262144,[14,1624,...|\n|        0|(262144,[2437,912...|\n|        0|(262144,[14,3026,...|\n|        0|(262144,[14,1804,...|\n+---------+--------------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "# tokenize\n",
    "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"words\")\n",
    "words_data = tokenizer.transform(dataset_spark)\n",
    "print('Words data schema:')\n",
    "words_data.printSchema()\n",
    "\n",
    "# terms frequency\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "features = hashingTF.transform(words_data)\n",
    "features.show(5)\n",
    "\n",
    "# inverse document frequency\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(features)\n",
    "tfidf_data = idfModel.transform(features)\n",
    "print('tf-idf data schema:')\n",
    "tfidf_data.printSchema()\n",
    "tfidf_data.select(\"sentiment\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of features: 262144\n"
    }
   ],
   "source": [
    "# count features  \n",
    "num_features = tfidf_data.select(\"features\").take(1)[0][\"features\"].toArray().shape[0]\n",
    "print('Number of features:', num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DenseMatrix(3, 2, [-0.4082, -0.8165, -0.4082, 0.8944, -0.4472, 0.0], 0)"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "# test svd on a toy RowMatrix\n",
    "rows = sparkSession.sparkContext.parallelize([[3, 1, 1], [-1, 3, 1]])\n",
    "rm = RowMatrix(rows)\n",
    "svd_model = rm.computeSVD(2, True)\n",
    "svd_model.U.rows.collect()\n",
    "svd_model.s\n",
    "svd_model.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[DenseVector([-0.7071, 0.7071]), DenseVector([-0.7071, -0.7071])]\n\nSingular values:\n [3.464101615137755,3.1622776601683795]\n\nEigenvectors:\n DenseMatrix([[-4.08248290e-01,  8.94427191e-01],\n             [-8.16496581e-01, -4.47213595e-01],\n             [-4.08248290e-01,  2.77555756e-17]])\n"
    }
   ],
   "source": [
    "# test SVD on a toy indexedRowsMatrix  \n",
    "indexedRows = sparkSession.sparkContext.parallelize(\n",
    "    [\n",
    "    (0, [1, 2, 3]), \n",
    "    (1, [4, 5, 6]),\n",
    "    (2, [7, 8, 9]), \n",
    "    (3, [10, 11, 12])\n",
    "    ])\n",
    "mat = IndexedRowMatrix(indexedRows)\n",
    "svd = mat.computeSVD(2, computeU=True)\n",
    "print(svd_model.U.rows.collect())\n",
    "print(\"\\nSingular values:\\n\", svd_model.s)\n",
    "print(\"\\nEigenvectors:\\n\", svd_model.V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://towardsdatascience.com/multi-class-text-classification-with-pyspark-7d78d022ed35  \n",
    "https://spark.apache.org/docs/latest/ml-features#tf-idf  \n",
    "    * how to run tf-idf on toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}