{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599236062985",
   "display_name": "Python 3.6.10 64-bit ('nlp_text_similarity': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Text Similarity\n",
    "### Techniques: tf-idf + svd\n",
    "### Technos: pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "* Spark 2.4.4 is installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup environment variables\n",
    "\n",
    "* workload: 1 hour to config (first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup SPARK environment variables\n",
    "import os\n",
    "import sys  \n",
    "os.environ['SPARK_HOME'] = '/usr/local/Cellar/apache-spark/2.4.4/libexec'\n",
    "os.environ['PYSPARK_PYTHON'] = '/Applications/anaconda3/envs/nlp_text_similarity/bin/python'  \n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/Applications/anaconda3/envs/nlp_text_similarity/bin/python'  \n",
    "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home'\n",
    "os.environ['PYTHONPATH'] = os.environ['SPARK_HOME'] + '/python/lib/'\n",
    "sys.path.insert(0, os.environ['SPARK_HOME'] + '/python/lib/py4j-0.10.7-src.zip')\n",
    "sys.path.insert(0, os.environ['SPARK_HOME'] + '/python/lib/pyspark.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list dependencies\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sparkSession\n",
    "sparkSession = SparkSession.builder.appName(\"my_app\").master(\"local[*]\").getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x111ffdd68>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://steeve.home:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>my_app_name</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# print spark session config\n",
    "sparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "sentenceData = sparkSession.createDataFrame([\n",
    "    (0, \"Python python Spark Spark\"),\n",
    "    (1, \"Python SQL\")],\n",
    " [\"document\", \"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------+--------------------+\n|document|            sentence|\n+--------+--------------------+\n|       0|Python python Spa...|\n|       1|          Python SQL|\n+--------+--------------------+\n\n"
    }
   ],
   "source": [
    "# show data\n",
    "sentenceData.show()"
   ]
  }
 ]
}